{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"17DEc-DRUz5_UCoA7pypBjO7bt27Sdwqn","authorship_tag":"ABX9TyPEXw5Y1BCcO5ps2T2Maeb/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from transformers import AutoTokenizer, MT5ForConditionalGeneration\n","import torch"],"metadata":{"id":"_LCmcZcsDojf","executionInfo":{"status":"ok","timestamp":1702352394322,"user_tz":-420,"elapsed":5262,"user":{"displayName":"Phúc Vũ Hoàng","userId":"11665276937167919799"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["model_path = '/content/drive/MyDrive/nlp/results/model/model3'\n","tokenizer_path = '/content/drive/MyDrive/nlp/results/model/token'\n"],"metadata":{"id":"HUs-gZlaDrZY","executionInfo":{"status":"ok","timestamp":1702352394322,"user_tz":-420,"elapsed":3,"user":{"displayName":"Phúc Vũ Hoàng","userId":"11665276937167919799"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["model = MT5ForConditionalGeneration.from_pretrained(model_path)\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I2yMVdCeDrtw","executionInfo":{"status":"ok","timestamp":1702352431799,"user_tz":-420,"elapsed":37480,"user":{"displayName":"Phúc Vũ Hoàng","userId":"11665276937167919799"}},"outputId":"7c121759-7906-42de-c6dd-39964b215a7a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgvH6IKlBiv7","executionInfo":{"status":"ok","timestamp":1702352439279,"user_tz":-420,"elapsed":7483,"user":{"displayName":"Phúc Vũ Hoàng","userId":"11665276937167919799"}},"outputId":"41fe44fd-7345-4894-e772-920d1dc2274c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MT5ForConditionalGeneration(\n","  (shared): Embedding(250102, 512)\n","  (encoder): MT5Stack(\n","    (embed_tokens): Embedding(250102, 512)\n","    (block): ModuleList(\n","      (0): MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): MT5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): MT5Stack(\n","    (embed_tokens): Embedding(250102, 512)\n","    (block): ModuleList(\n","      (0): MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 6)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerCrossAttention(\n","            (EncDecAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-7): 7 x MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerCrossAttention(\n","            (EncDecAttention): MT5Attention(\n","              (q): Linear(in_features=512, out_features=384, bias=False)\n","              (k): Linear(in_features=512, out_features=384, bias=False)\n","              (v): Linear(in_features=512, out_features=384, bias=False)\n","              (o): Linear(in_features=384, out_features=512, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n","              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n","              (wo): Linear(in_features=1024, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): MT5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=250102, bias=False)\n",")"]},"metadata":{},"execution_count":4}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"code","source":["text=\"<en> Tom is a very secretive person \"\n","print(text)\n","encoded_text = tokenizer(text, return_tensors='pt').to(device)\n","translated = model.generate(**encoded_text)\n","translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n","print(translated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adwHSdrvD_de","executionInfo":{"status":"ok","timestamp":1702352560170,"user_tz":-420,"elapsed":1690,"user":{"displayName":"Phúc Vũ Hoàng","userId":"11665276937167919799"}},"outputId":"72209a20-4fc4-4a7a-9dba-4932307e8eaf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["<en> Tom is a very secretive person \n","tom là một người rất tự tự tự tự tự tự tự tự tự tự \n"]}]},{"cell_type":"code","source":["\n","text=\"<fr> je suis satisfait des résultats \"\n","print(text)\n","encoded_text = tokenizer(text, return_tensors='pt').to(device)\n","translated = model.generate(**encoded_text)\n","translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n","print(translated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOOw6KxVHFBA","executionInfo":{"status":"ok","timestamp":1702352565077,"user_tz":-420,"elapsed":1708,"user":{"displayName":"Phúc Vũ Hoàng","userId":"11665276937167919799"}},"outputId":"42ff8fda-629b-4314-f885-2d3a270378f8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["<fr> je suis satisfait des résultats \n","tôi rất vui vẻ về những lời khuyên\n"]}]}]}