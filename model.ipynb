{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hX404lnsqg_",
        "outputId": "ca464945-e12b-43b3-8d6b-41c5fa24b901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQsTn5gexFLL"
      },
      "outputs": [],
      "source": [
        "from transformers import MT5ForConditionalGeneration,AutoModelForSeq2SeqLM, T5Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import string\n",
        "import pandas as pd\n",
        "import sentencepiece\n",
        "import accelerate\n",
        "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9U9LSjPxeJh"
      },
      "outputs": [],
      "source": [
        "def read_data(file_path, num_lines=150000):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return [next(f).strip() for _ in range(num_lines)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lVLrF4Z6-0m",
        "outputId": "ce25ea1d-4735-4a3a-da00-c473651bde2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5I5T3_OxhFP"
      },
      "outputs": [],
      "source": [
        "en_sents = read_data(\"/content/drive/MyDrive/new/data/en_sents.txt\")\n",
        "fr_sents = read_data(\"/content/drive/MyDrive/new/data/fr_sents.txt\")\n",
        "vi_sents = read_data(\"/content/drive/MyDrive/new/data/vi_sents.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z5zyfzMExrJw",
        "outputId": "3da5424b-1b85-4ec7-e336-988be6a90fac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  en  \\\n",
              "0         Please put the dustpan in the broom closet   \n",
              "1                             Be quiet for a moment.   \n",
              "2                                          Read this   \n",
              "3  Tom persuaded the store manager to give him ba...   \n",
              "4        Friendship consists of mutual understanding   \n",
              "\n",
              "                                                  fr  \\\n",
              "0  Veuillez placer la pelle à poussière dans le p...   \n",
              "1                               silencieux un moment   \n",
              "2                                             lis ça   \n",
              "3  Tom a persuadé le gérant du magasin de lui ren...   \n",
              "4          L'amitié inclut la compréhension mutuelle   \n",
              "\n",
              "                                                  vi  \n",
              "0      xin vui lòng đặt người quét rác trong tủ chổi  \n",
              "1                                    im lặng một lát  \n",
              "2                                            đọc này  \n",
              "3  tom thuyết phục người quản lý cửa hàng trả lại...  \n",
              "4             tình bạn bao gồm sự hiểu biết lẫn nhau  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11f0279f-9038-4bab-90b6-304dc88b65a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "      <th>vi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please put the dustpan in the broom closet</td>\n",
              "      <td>Veuillez placer la pelle à poussière dans le p...</td>\n",
              "      <td>xin vui lòng đặt người quét rác trong tủ chổi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Be quiet for a moment.</td>\n",
              "      <td>silencieux un moment</td>\n",
              "      <td>im lặng một lát</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Read this</td>\n",
              "      <td>lis ça</td>\n",
              "      <td>đọc này</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tom persuaded the store manager to give him ba...</td>\n",
              "      <td>Tom a persuadé le gérant du magasin de lui ren...</td>\n",
              "      <td>tom thuyết phục người quản lý cửa hàng trả lại...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Friendship consists of mutual understanding</td>\n",
              "      <td>L'amitié inclut la compréhension mutuelle</td>\n",
              "      <td>tình bạn bao gồm sự hiểu biết lẫn nhau</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11f0279f-9038-4bab-90b6-304dc88b65a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11f0279f-9038-4bab-90b6-304dc88b65a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11f0279f-9038-4bab-90b6-304dc88b65a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-95cbdab8-e44a-49c4-8b07-5c14e2c2d72e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95cbdab8-e44a-49c4-8b07-5c14e2c2d72e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-95cbdab8-e44a-49c4-8b07-5c14e2c2d72e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"en\": en_sents,\n",
        "    \"fr\": fr_sents,\n",
        "    \"vi\": vi_sents\n",
        "})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWRWl2wP5eiT"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Loại bỏ dấu câu\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Chuyển thành chữ thường\n",
        "    text = text.lower()\n",
        "    # Loại bỏ khoảng trắng thừa\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Tiền xử lý dữ liệu\n",
        "en_sents = [preprocess_text(sent) for sent in en_sents]\n",
        "fr_sents = [preprocess_text(sent) for sent in fr_sents]\n",
        "vi_sents = [preprocess_text(sent) for sent in vi_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1wUTf50K5jhX",
        "outputId": "9c464393-952f-49f0-9c04-feeaa6118b4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  en  \\\n",
              "0         please put the dustpan in the broom closet   \n",
              "1                              be quiet for a moment   \n",
              "2                                          read this   \n",
              "3  tom persuaded the store manager to give him ba...   \n",
              "4        friendship consists of mutual understanding   \n",
              "\n",
              "                                                  fr  \\\n",
              "0  veuillez placer la pelle à poussière dans le p...   \n",
              "1                               silencieux un moment   \n",
              "2                                             lis ça   \n",
              "3  tom a persuadé le gérant du magasin de lui ren...   \n",
              "4           lamitié inclut la compréhension mutuelle   \n",
              "\n",
              "                                                  vi  \n",
              "0      xin vui lòng đặt người quét rác trong tủ chổi  \n",
              "1                                    im lặng một lát  \n",
              "2                                            đọc này  \n",
              "3  tom thuyết phục người quản lý cửa hàng trả lại...  \n",
              "4             tình bạn bao gồm sự hiểu biết lẫn nhau  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a327334b-c688-4e2d-b8ea-1dc4c627ab28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "      <th>vi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>please put the dustpan in the broom closet</td>\n",
              "      <td>veuillez placer la pelle à poussière dans le p...</td>\n",
              "      <td>xin vui lòng đặt người quét rác trong tủ chổi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>be quiet for a moment</td>\n",
              "      <td>silencieux un moment</td>\n",
              "      <td>im lặng một lát</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>read this</td>\n",
              "      <td>lis ça</td>\n",
              "      <td>đọc này</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tom persuaded the store manager to give him ba...</td>\n",
              "      <td>tom a persuadé le gérant du magasin de lui ren...</td>\n",
              "      <td>tom thuyết phục người quản lý cửa hàng trả lại...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>friendship consists of mutual understanding</td>\n",
              "      <td>lamitié inclut la compréhension mutuelle</td>\n",
              "      <td>tình bạn bao gồm sự hiểu biết lẫn nhau</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a327334b-c688-4e2d-b8ea-1dc4c627ab28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a327334b-c688-4e2d-b8ea-1dc4c627ab28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a327334b-c688-4e2d-b8ea-1dc4c627ab28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1d2b09d2-ffb7-45fa-add9-4c858beaf1c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d2b09d2-ffb7-45fa-add9-4c858beaf1c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1d2b09d2-ffb7-45fa-add9-4c858beaf1c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"en\": en_sents,\n",
        "    \"fr\": fr_sents,\n",
        "    \"vi\": vi_sents\n",
        "})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVrvJD7V7wvj"
      },
      "outputs": [],
      "source": [
        "# Tiền xử lý dữ liệu\n",
        "source_texts = [f\"<en> {en_sent}\" for en_sent in en_sents] + [f\"<fr> {fr_sent}\" for fr_sent in fr_sents]\n",
        "target_texts = vi_sents + vi_sents  # Gộp dữ liệu tiếng Việt lại"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "NVsiqbItskpJ",
        "outputId": "1a8c989e-2a1c-4d95-a7b9-717bdb40d68c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        input_text  \\\n",
              "213076  <fr> rentrez à la maison en toute sécurité   \n",
              "178195            <fr> nous découvrirons la vérité   \n",
              "205138              <fr> veuxtu dîner ici avec moi   \n",
              "165955    <fr> jai dit à tom tout ce que je savais   \n",
              "84271                       <en> ill figure it out   \n",
              "32900                     <en> this man is chinese   \n",
              "\n",
              "                                        target_text  \n",
              "213076                               về nhà an toàn  \n",
              "178195                   chúng ta sẽ tìm ra sự thật  \n",
              "205138                  bạn sẽ ăn tối ở đây với tôi  \n",
              "165955  tôi đã nói với tom tất cả những gì tôi biết  \n",
              "84271                              tôi sẽ tìm ra nó  \n",
              "32900         người đàn ông này là người trung quốc  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9b850d0-043c-4665-b02c-91eab058a96f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213076</th>\n",
              "      <td>&lt;fr&gt; rentrez à la maison en toute sécurité</td>\n",
              "      <td>về nhà an toàn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178195</th>\n",
              "      <td>&lt;fr&gt; nous découvrirons la vérité</td>\n",
              "      <td>chúng ta sẽ tìm ra sự thật</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205138</th>\n",
              "      <td>&lt;fr&gt; veuxtu dîner ici avec moi</td>\n",
              "      <td>bạn sẽ ăn tối ở đây với tôi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165955</th>\n",
              "      <td>&lt;fr&gt; jai dit à tom tout ce que je savais</td>\n",
              "      <td>tôi đã nói với tom tất cả những gì tôi biết</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84271</th>\n",
              "      <td>&lt;en&gt; ill figure it out</td>\n",
              "      <td>tôi sẽ tìm ra nó</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32900</th>\n",
              "      <td>&lt;en&gt; this man is chinese</td>\n",
              "      <td>người đàn ông này là người trung quốc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9b850d0-043c-4665-b02c-91eab058a96f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9b850d0-043c-4665-b02c-91eab058a96f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9b850d0-043c-4665-b02c-91eab058a96f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18421dc9-944b-4c6a-ab39-27fb39b8f519\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18421dc9-944b-4c6a-ab39-27fb39b8f519')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18421dc9-944b-4c6a-ab39-27fb39b8f519 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df = pd.DataFrame({\n",
        "    \"input_text\": source_texts,\n",
        "    \"target_text\": target_texts,\n",
        "})\n",
        "df.sample(6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xáo trộn DataFrame\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Chia thành train, eval, và test theo tỉ lệ mong muốn (ví dụ: 80-10-10)\n",
        "train_df, eval_df = train_test_split(df_shuffled, test_size=0.1, random_state=42)\n",
        "\n",
        "# In kích thước của từng tập dữ liệu\n",
        "print(\"Train set size:\", len(train_df))\n",
        "print(\"Eval set size:\", len(eval_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa5WbbdiQw8X",
        "outputId": "7da7cc64-20e3-42ec-cf7c-cc2a7207c1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 270000\n",
            "Eval set size: 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "OTYXhRDORIGd",
        "outputId": "94310a7b-59e0-42a2-8036-0ecdfa755703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input_text  \\\n",
              "299465  <fr> elle a mordu plus quelle ne pouvait mâche...   \n",
              "81922                        <en> im going to take my car   \n",
              "143673  <en> they came up with a plan after a long dis...   \n",
              "208449                        <fr> dick ma passé la photo   \n",
              "293179         <fr> leurs parents sont plus âgés que nous   \n",
              "...                                                   ...   \n",
              "119879                      <en> help me lift the package   \n",
              "259178        <en> is there anything you want me to bring   \n",
              "131932  <fr> je narrive pas à croire à quel point tu e...   \n",
              "146867                               <en> go back to work   \n",
              "121958  <en> i thought you didnt want to talk about th...   \n",
              "\n",
              "                                              target_text  \n",
              "299465   cô cắn nhiều hơn những gì cô có thể nhai và cười  \n",
              "81922                                tôi sẽ đi xe của tôi  \n",
              "143673  họ đã đưa ra một kế hoạch sau một cuộc thảo lu...  \n",
              "208449                   tinh ranh truyền cho tôi bức ảnh  \n",
              "293179                cha mẹ của họ lớn tuổi hơn chúng ta  \n",
              "...                                                   ...  \n",
              "119879                                  giúp tôi nâng gói  \n",
              "259178            có bất cứ điều gì bạn muốn tôi mang lại  \n",
              "131932         tôi không thể tin rằng bạn đẹp như thế nào  \n",
              "146867                                   trở lại làm việc  \n",
              "121958       tôi nghĩ bạn không muốn nói về những thứ này  \n",
              "\n",
              "[270000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f2707de-0fc0-4d87-ad3d-c8c3132bcad8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>299465</th>\n",
              "      <td>&lt;fr&gt; elle a mordu plus quelle ne pouvait mâche...</td>\n",
              "      <td>cô cắn nhiều hơn những gì cô có thể nhai và cười</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81922</th>\n",
              "      <td>&lt;en&gt; im going to take my car</td>\n",
              "      <td>tôi sẽ đi xe của tôi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143673</th>\n",
              "      <td>&lt;en&gt; they came up with a plan after a long dis...</td>\n",
              "      <td>họ đã đưa ra một kế hoạch sau một cuộc thảo lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208449</th>\n",
              "      <td>&lt;fr&gt; dick ma passé la photo</td>\n",
              "      <td>tinh ranh truyền cho tôi bức ảnh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293179</th>\n",
              "      <td>&lt;fr&gt; leurs parents sont plus âgés que nous</td>\n",
              "      <td>cha mẹ của họ lớn tuổi hơn chúng ta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119879</th>\n",
              "      <td>&lt;en&gt; help me lift the package</td>\n",
              "      <td>giúp tôi nâng gói</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259178</th>\n",
              "      <td>&lt;en&gt; is there anything you want me to bring</td>\n",
              "      <td>có bất cứ điều gì bạn muốn tôi mang lại</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>&lt;fr&gt; je narrive pas à croire à quel point tu e...</td>\n",
              "      <td>tôi không thể tin rằng bạn đẹp như thế nào</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146867</th>\n",
              "      <td>&lt;en&gt; go back to work</td>\n",
              "      <td>trở lại làm việc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121958</th>\n",
              "      <td>&lt;en&gt; i thought you didnt want to talk about th...</td>\n",
              "      <td>tôi nghĩ bạn không muốn nói về những thứ này</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f2707de-0fc0-4d87-ad3d-c8c3132bcad8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f2707de-0fc0-4d87-ad3d-c8c3132bcad8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f2707de-0fc0-4d87-ad3d-c8c3132bcad8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-781f7587-f119-4e90-8f71-d9dc123a4cf0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-781f7587-f119-4e90-8f71-d9dc123a4cf0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-781f7587-f119-4e90-8f71-d9dc123a4cf0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ec542efe-78d8-45f5-a00b-8435bf4d82f1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ec542efe-78d8-45f5-a00b-8435bf4d82f1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "npWhKamERLu3",
        "outputId": "5ce94fe2-c7f1-422d-8260-e27cc9ebd7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input_text  \\\n",
              "4941    <fr> sa gentillesse ma donné une boule dans la...   \n",
              "51775           <en> i thought youd be too busy to see me   \n",
              "115253                <fr> vous devez venir immédiatement   \n",
              "299321  <en> tom took a beer out of the fridge and han...   \n",
              "173570            <en> this childs mother is an announcer   \n",
              "...                                                   ...   \n",
              "199500            <en> tom and mary laughed at each other   \n",
              "244038                      <fr> elle brûlait de jalousie   \n",
              "79446                             <en> whats the forecast   \n",
              "276390                         <en> i think ill wait here   \n",
              "144864              <fr> tu ne peux pas faire ça avec tom   \n",
              "\n",
              "                                              target_text  \n",
              "4941    lòng tốt của cô ấy cho tôi một khối u trong cổ...  \n",
              "51775                  tôi nghĩ bạn sẽ quá bận để gặp tôi  \n",
              "115253                      bạn cần phải đến ngay lập tức  \n",
              "299321     tom lấy bia ra khỏi tủ lạnh và đưa nó cho mary  \n",
              "173570          mẹ của đứa trẻ này là một phát thanh viên  \n",
              "...                                                   ...  \n",
              "199500                          tom và mary cười với nhau  \n",
              "244038                    cô ấy đang bùng cháy vì ghen tị  \n",
              "79446                             dự báo thời tiết nói gì  \n",
              "276390                          tôi nghĩ tôi sẽ đợi ở đây  \n",
              "144864                 bạn không thể làm điều này với tom  \n",
              "\n",
              "[30000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f7a69cc-5eea-4395-8318-4671dec40351\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4941</th>\n",
              "      <td>&lt;fr&gt; sa gentillesse ma donné une boule dans la...</td>\n",
              "      <td>lòng tốt của cô ấy cho tôi một khối u trong cổ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51775</th>\n",
              "      <td>&lt;en&gt; i thought youd be too busy to see me</td>\n",
              "      <td>tôi nghĩ bạn sẽ quá bận để gặp tôi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115253</th>\n",
              "      <td>&lt;fr&gt; vous devez venir immédiatement</td>\n",
              "      <td>bạn cần phải đến ngay lập tức</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299321</th>\n",
              "      <td>&lt;en&gt; tom took a beer out of the fridge and han...</td>\n",
              "      <td>tom lấy bia ra khỏi tủ lạnh và đưa nó cho mary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173570</th>\n",
              "      <td>&lt;en&gt; this childs mother is an announcer</td>\n",
              "      <td>mẹ của đứa trẻ này là một phát thanh viên</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199500</th>\n",
              "      <td>&lt;en&gt; tom and mary laughed at each other</td>\n",
              "      <td>tom và mary cười với nhau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244038</th>\n",
              "      <td>&lt;fr&gt; elle brûlait de jalousie</td>\n",
              "      <td>cô ấy đang bùng cháy vì ghen tị</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79446</th>\n",
              "      <td>&lt;en&gt; whats the forecast</td>\n",
              "      <td>dự báo thời tiết nói gì</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276390</th>\n",
              "      <td>&lt;en&gt; i think ill wait here</td>\n",
              "      <td>tôi nghĩ tôi sẽ đợi ở đây</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144864</th>\n",
              "      <td>&lt;fr&gt; tu ne peux pas faire ça avec tom</td>\n",
              "      <td>bạn không thể làm điều này với tom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f7a69cc-5eea-4395-8318-4671dec40351')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f7a69cc-5eea-4395-8318-4671dec40351 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f7a69cc-5eea-4395-8318-4671dec40351');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b5469343-f6e7-4434-92da-c5b7995b61d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5469343-f6e7-4434-92da-c5b7995b61d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b5469343-f6e7-4434-92da-c5b7995b61d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1f473775-8a7d-4d9c-b5f0-1c28662b30f3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eval_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1f473775-8a7d-4d9c-b5f0-1c28662b30f3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('eval_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.reset_index(drop=True)\n",
        "eval_df = eval_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5rqNUzxF4sea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_repo = 'google/mt5-small'\n",
        "model_path= '/content/drive/MyDrive/new/results/model/mt5_translation.pt'\n",
        "max_seq_len = 40"
      ],
      "metadata": {
        "id": "C-ph0PDPDprv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ttsyrb2o4fIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27adb4ce-77ef-4d35-8076-a589b4a7d353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_repo)\n",
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "DddOk5JlJOeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "special_tokens_dict = {'additional_special_tokens': ['<en>', '<fr>']}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWu5ngbds6kC",
        "outputId": "7eb24d90-55fd-420a-8e38-503ad1d56963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(250102, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.max_length=40"
      ],
      "metadata": {
        "id": "qULwb8ErIq3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(tokenizer.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYUHnVMLEDsS",
        "outputId": "42452dfe-e645-4455-b466-e614ac07d353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250102"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8hGQQTwtH7A",
        "outputId": "38b1d314-f272-4932-977f-ea126e40c160"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['</s>', '<unk>', '<pad>', '<en>', '<fr>']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tokenizer.all_special_tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(examples):\n",
        "    inputs = tokenizer(examples['input_text'], truncation=True, max_length=max_seq_len, padding='max_length', return_tensors='pt')\n",
        "    targets = tokenizer(examples['target_text'], truncation=True, max_length=max_seq_len, padding='max_length', return_tensors='pt')\n",
        "    inputs['labels'] = targets['input_ids']\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "vNKQIH4Nu3p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode dữ liệu\n",
        "train_dataset = train_df.apply(encode, axis=1)\n",
        "eval_dataset = eval_df.apply(encode, axis=1)"
      ],
      "metadata": {
        "id": "5Nv9R47Cu3k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_dataset.iloc[0]\n",
        "\n",
        "print(f\"input_text: {train_df.iloc[0]['input_text']}\")\n",
        "print(f\"target_text: {train_df.iloc[0]['target_text']}\")\n",
        "print(f\"input_ids: {sample['input_ids']}\")\n",
        "print(f\"attention_mask: {sample['attention_mask']}\")\n",
        "print(f\"labels: {sample['labels']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNGtM2C61Gab",
        "outputId": "3b6c6d54-8732-435d-aaa5-f7590e0fbe76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_text: <fr> elle a mordu plus quelle ne pouvait mâcher et a ri\n",
            "target_text: cô cắn nhiều hơn những gì cô có thể nhai và cười\n",
            "input_ids: tensor([[250101,  15679,    259,    262,  81873,    273,   1245,    259,  16141,\n",
            "            448,   2001,  65040,  60730,   5625,    383,    259,    262,   1418,\n",
            "              1,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "              0,      0,      0,      0]])\n",
            "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "labels: tensor([[ 6740,   317,  6701,   677,  1990,   382,  2238,   259,   272,  1992,\n",
            "           259,   318,  1135,  6740,   885,   394,   924,   677,   741,   259,\n",
            "           793,   317, 25341,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo DataLoaders cho tập huấn luyện và đánh giá\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # Dữ liệu huấn luyện\n",
        "            sampler = RandomSampler(train_dataset), # Chọn mẫu ngẫu nhiên để huấn luyện\n",
        "            batch_size = batch_size # Huấn luyện với batch_size này\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            eval_dataset, # Dữ liệu đánh giá\n",
        "            sampler = SequentialSampler(eval_dataset), # Chọn mẫu tuần tự để đánh giá\n",
        "            batch_size = batch_size # Đánh giá với batch_size này\n",
        "        )"
      ],
      "metadata": {
        "id": "et6WmrUx4gaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "total_steps = len(train_dataset) * num_epochs\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkn8NBLz1gmR",
        "outputId": "6ebea0f3-8238-4d10-cd02-74673f6d769d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "6KSW3gQ-62ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Huấn luyện mô hình\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        input_ids = batch['input_ids'].squeeze().to(device)\n",
        "        attention_mask = batch['attention_mask'].squeeze().to(device)\n",
        "        labels = batch['labels'].squeeze().to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # In ra loss sau mỗi 100 bước\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            print(f'  Batch {step}  of  {len(train_dataloader)}.    Loss: {loss.item()}')\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    print(f'Average training loss: {avg_train_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb-9famE2xri",
        "outputId": "77aa64ce-f50f-435b-9592-59c74c470fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "  Batch 100  of  16875.    Loss: 41.421974182128906\n",
            "  Batch 200  of  16875.    Loss: 42.56519317626953\n",
            "  Batch 300  of  16875.    Loss: 37.97869110107422\n",
            "  Batch 400  of  16875.    Loss: 34.817527770996094\n",
            "  Batch 500  of  16875.    Loss: 33.18784713745117\n",
            "  Batch 600  of  16875.    Loss: 30.99874496459961\n",
            "  Batch 700  of  16875.    Loss: 28.66680908203125\n",
            "  Batch 800  of  16875.    Loss: 27.971582412719727\n",
            "  Batch 900  of  16875.    Loss: 24.539335250854492\n",
            "  Batch 1000  of  16875.    Loss: 23.766845703125\n",
            "  Batch 1100  of  16875.    Loss: 22.85208511352539\n",
            "  Batch 1200  of  16875.    Loss: 21.820247650146484\n",
            "  Batch 1300  of  16875.    Loss: 19.88681411743164\n",
            "  Batch 1400  of  16875.    Loss: 21.37656021118164\n",
            "  Batch 1500  of  16875.    Loss: 18.614505767822266\n",
            "  Batch 1600  of  16875.    Loss: 16.65066146850586\n",
            "  Batch 1700  of  16875.    Loss: 15.956418991088867\n",
            "  Batch 1800  of  16875.    Loss: 15.463096618652344\n",
            "  Batch 1900  of  16875.    Loss: 15.209953308105469\n",
            "  Batch 2000  of  16875.    Loss: 13.313563346862793\n",
            "  Batch 2100  of  16875.    Loss: 12.360726356506348\n",
            "  Batch 2200  of  16875.    Loss: 11.864033699035645\n",
            "  Batch 2300  of  16875.    Loss: 10.874619483947754\n",
            "  Batch 2400  of  16875.    Loss: 11.295537948608398\n",
            "  Batch 2500  of  16875.    Loss: 9.539108276367188\n",
            "  Batch 2600  of  16875.    Loss: 9.252415657043457\n",
            "  Batch 2700  of  16875.    Loss: 8.665290832519531\n",
            "  Batch 2800  of  16875.    Loss: 8.067245483398438\n",
            "  Batch 2900  of  16875.    Loss: 7.933053016662598\n",
            "  Batch 3000  of  16875.    Loss: 7.532267093658447\n",
            "  Batch 3100  of  16875.    Loss: 7.403157711029053\n",
            "  Batch 3200  of  16875.    Loss: 6.815283298492432\n",
            "  Batch 3300  of  16875.    Loss: 6.278051853179932\n",
            "  Batch 3400  of  16875.    Loss: 5.778225898742676\n",
            "  Batch 3500  of  16875.    Loss: 5.777472972869873\n",
            "  Batch 3600  of  16875.    Loss: 5.285656929016113\n",
            "  Batch 3700  of  16875.    Loss: 4.898802757263184\n",
            "  Batch 3800  of  16875.    Loss: 5.0038299560546875\n",
            "  Batch 3900  of  16875.    Loss: 4.650106906890869\n",
            "  Batch 4000  of  16875.    Loss: 4.832303524017334\n",
            "  Batch 4100  of  16875.    Loss: 3.6087582111358643\n",
            "  Batch 4200  of  16875.    Loss: 3.4498953819274902\n",
            "  Batch 4300  of  16875.    Loss: 3.6505393981933594\n",
            "  Batch 4400  of  16875.    Loss: 3.1900322437286377\n",
            "  Batch 4500  of  16875.    Loss: 3.6258339881896973\n",
            "  Batch 4600  of  16875.    Loss: 3.6357619762420654\n",
            "  Batch 4700  of  16875.    Loss: 2.818676471710205\n",
            "  Batch 4800  of  16875.    Loss: 3.280410051345825\n",
            "  Batch 4900  of  16875.    Loss: 2.8480653762817383\n",
            "  Batch 5000  of  16875.    Loss: 2.84140944480896\n",
            "  Batch 5100  of  16875.    Loss: 2.941711187362671\n",
            "  Batch 5200  of  16875.    Loss: 3.08720326423645\n",
            "  Batch 5300  of  16875.    Loss: 2.9554123878479004\n",
            "  Batch 5400  of  16875.    Loss: 2.7221322059631348\n",
            "  Batch 5500  of  16875.    Loss: 2.7374074459075928\n",
            "  Batch 5600  of  16875.    Loss: 2.779139995574951\n",
            "  Batch 5700  of  16875.    Loss: 2.645331621170044\n",
            "  Batch 5800  of  16875.    Loss: 2.5868844985961914\n",
            "  Batch 5900  of  16875.    Loss: 2.9657516479492188\n",
            "  Batch 6000  of  16875.    Loss: 2.324047565460205\n",
            "  Batch 6100  of  16875.    Loss: 2.7024388313293457\n",
            "  Batch 6200  of  16875.    Loss: 2.1018948554992676\n",
            "  Batch 6300  of  16875.    Loss: 2.5970888137817383\n",
            "  Batch 6400  of  16875.    Loss: 2.5946907997131348\n",
            "  Batch 6500  of  16875.    Loss: 2.1258840560913086\n",
            "  Batch 6600  of  16875.    Loss: 2.464491605758667\n",
            "  Batch 6700  of  16875.    Loss: 2.0572562217712402\n",
            "  Batch 6800  of  16875.    Loss: 2.538031816482544\n",
            "  Batch 6900  of  16875.    Loss: 1.6334865093231201\n",
            "  Batch 7000  of  16875.    Loss: 2.2617926597595215\n",
            "  Batch 7100  of  16875.    Loss: 2.354525089263916\n",
            "  Batch 7200  of  16875.    Loss: 1.9830658435821533\n",
            "  Batch 7300  of  16875.    Loss: 1.9773451089859009\n",
            "  Batch 7400  of  16875.    Loss: 1.8486974239349365\n",
            "  Batch 7500  of  16875.    Loss: 2.0605621337890625\n",
            "  Batch 7600  of  16875.    Loss: 2.052398920059204\n",
            "  Batch 7700  of  16875.    Loss: 1.7378406524658203\n",
            "  Batch 7800  of  16875.    Loss: 1.8476550579071045\n",
            "  Batch 7900  of  16875.    Loss: 1.9023005962371826\n",
            "  Batch 8000  of  16875.    Loss: 2.0140185356140137\n",
            "  Batch 8100  of  16875.    Loss: 1.7478039264678955\n",
            "  Batch 8200  of  16875.    Loss: 1.6255419254302979\n",
            "  Batch 8300  of  16875.    Loss: 1.712720513343811\n",
            "  Batch 8400  of  16875.    Loss: 1.719294786453247\n",
            "  Batch 8500  of  16875.    Loss: 1.908943772315979\n",
            "  Batch 8600  of  16875.    Loss: 1.751349687576294\n",
            "  Batch 8700  of  16875.    Loss: 1.593632698059082\n",
            "  Batch 8800  of  16875.    Loss: 1.789110541343689\n",
            "  Batch 8900  of  16875.    Loss: 1.3870728015899658\n",
            "  Batch 9000  of  16875.    Loss: 1.7215543985366821\n",
            "  Batch 9100  of  16875.    Loss: 1.574161171913147\n",
            "  Batch 9200  of  16875.    Loss: 1.5614835023880005\n",
            "  Batch 9300  of  16875.    Loss: 1.9743016958236694\n",
            "  Batch 9400  of  16875.    Loss: 1.5903939008712769\n",
            "  Batch 9500  of  16875.    Loss: 1.5969682931900024\n",
            "  Batch 9600  of  16875.    Loss: 1.5120155811309814\n",
            "  Batch 9700  of  16875.    Loss: 1.3615989685058594\n",
            "  Batch 9800  of  16875.    Loss: 1.7640231847763062\n",
            "  Batch 9900  of  16875.    Loss: 1.6487442255020142\n",
            "  Batch 10000  of  16875.    Loss: 1.4981569051742554\n",
            "  Batch 10100  of  16875.    Loss: 1.3120509386062622\n",
            "  Batch 10200  of  16875.    Loss: 1.409421682357788\n",
            "  Batch 10300  of  16875.    Loss: 1.2141668796539307\n",
            "  Batch 10400  of  16875.    Loss: 1.264509677886963\n",
            "  Batch 10500  of  16875.    Loss: 1.2957578897476196\n",
            "  Batch 10600  of  16875.    Loss: 1.2806217670440674\n",
            "  Batch 10700  of  16875.    Loss: 1.363276720046997\n",
            "  Batch 10800  of  16875.    Loss: 1.4212363958358765\n",
            "  Batch 10900  of  16875.    Loss: 1.2404767274856567\n",
            "  Batch 11000  of  16875.    Loss: 1.168657898902893\n",
            "  Batch 11100  of  16875.    Loss: 1.495958685874939\n",
            "  Batch 11200  of  16875.    Loss: 1.329722285270691\n",
            "  Batch 11300  of  16875.    Loss: 1.50760018825531\n",
            "  Batch 11400  of  16875.    Loss: 1.3670541048049927\n",
            "  Batch 11500  of  16875.    Loss: 1.5222793817520142\n",
            "  Batch 11600  of  16875.    Loss: 1.468436360359192\n",
            "  Batch 11700  of  16875.    Loss: 1.0454237461090088\n",
            "  Batch 11800  of  16875.    Loss: 1.272660493850708\n",
            "  Batch 11900  of  16875.    Loss: 1.384826421737671\n",
            "  Batch 12000  of  16875.    Loss: 1.3725545406341553\n",
            "  Batch 12100  of  16875.    Loss: 1.2904068231582642\n",
            "  Batch 12200  of  16875.    Loss: 1.0918523073196411\n",
            "  Batch 12300  of  16875.    Loss: 1.2708103656768799\n",
            "  Batch 12400  of  16875.    Loss: 1.1830120086669922\n",
            "  Batch 12500  of  16875.    Loss: 1.1769468784332275\n",
            "  Batch 12600  of  16875.    Loss: 1.2786223888397217\n",
            "  Batch 12700  of  16875.    Loss: 1.3069658279418945\n",
            "  Batch 12800  of  16875.    Loss: 1.21889066696167\n",
            "  Batch 12900  of  16875.    Loss: 1.2989096641540527\n",
            "  Batch 13000  of  16875.    Loss: 1.292939305305481\n",
            "  Batch 13100  of  16875.    Loss: 1.1871610879898071\n",
            "  Batch 13200  of  16875.    Loss: 1.3187159299850464\n",
            "  Batch 13300  of  16875.    Loss: 1.112794041633606\n",
            "  Batch 13400  of  16875.    Loss: 0.9694789052009583\n",
            "  Batch 13500  of  16875.    Loss: 1.3664896488189697\n",
            "  Batch 13600  of  16875.    Loss: 1.389807939529419\n",
            "  Batch 13700  of  16875.    Loss: 1.2604488134384155\n",
            "  Batch 13800  of  16875.    Loss: 1.3641815185546875\n",
            "  Batch 13900  of  16875.    Loss: 1.4226759672164917\n",
            "  Batch 14000  of  16875.    Loss: 1.6646827459335327\n",
            "  Batch 14100  of  16875.    Loss: 1.1965062618255615\n",
            "  Batch 14200  of  16875.    Loss: 1.2398179769515991\n",
            "  Batch 14300  of  16875.    Loss: 1.1727895736694336\n",
            "  Batch 14400  of  16875.    Loss: 1.31064772605896\n",
            "  Batch 14500  of  16875.    Loss: 1.3669601678848267\n",
            "  Batch 14600  of  16875.    Loss: 1.3832789659500122\n",
            "  Batch 14700  of  16875.    Loss: 1.0867035388946533\n",
            "  Batch 14800  of  16875.    Loss: 1.432318925857544\n",
            "  Batch 14900  of  16875.    Loss: 1.063878059387207\n",
            "  Batch 15000  of  16875.    Loss: 0.9119483232498169\n",
            "  Batch 15100  of  16875.    Loss: 1.5355526208877563\n",
            "  Batch 15200  of  16875.    Loss: 1.2393486499786377\n",
            "  Batch 15300  of  16875.    Loss: 1.3286067247390747\n",
            "  Batch 15400  of  16875.    Loss: 1.137563943862915\n",
            "  Batch 15500  of  16875.    Loss: 1.2294753789901733\n",
            "  Batch 15600  of  16875.    Loss: 1.1910475492477417\n",
            "  Batch 15700  of  16875.    Loss: 1.2798444032669067\n",
            "  Batch 15800  of  16875.    Loss: 1.4653985500335693\n",
            "  Batch 15900  of  16875.    Loss: 1.1309787034988403\n",
            "  Batch 16000  of  16875.    Loss: 1.151050090789795\n",
            "  Batch 16100  of  16875.    Loss: 1.0054118633270264\n",
            "  Batch 16200  of  16875.    Loss: 0.9897642135620117\n",
            "  Batch 16300  of  16875.    Loss: 1.099446415901184\n",
            "  Batch 16400  of  16875.    Loss: 1.2169570922851562\n",
            "  Batch 16500  of  16875.    Loss: 1.2124638557434082\n",
            "  Batch 16600  of  16875.    Loss: 1.0108025074005127\n",
            "  Batch 16700  of  16875.    Loss: 1.059561014175415\n",
            "  Batch 16800  of  16875.    Loss: 1.3131136894226074\n",
            "Average training loss: 5.372796887920521\n",
            "Epoch 2/5\n",
            "----------\n",
            "  Batch 100  of  16875.    Loss: 0.9221925735473633\n",
            "  Batch 200  of  16875.    Loss: 0.8801819682121277\n",
            "  Batch 300  of  16875.    Loss: 1.141796588897705\n",
            "  Batch 400  of  16875.    Loss: 1.031244158744812\n",
            "  Batch 500  of  16875.    Loss: 0.8724888563156128\n",
            "  Batch 600  of  16875.    Loss: 0.7943658828735352\n",
            "  Batch 700  of  16875.    Loss: 1.34807550907135\n",
            "  Batch 800  of  16875.    Loss: 1.1320236921310425\n",
            "  Batch 900  of  16875.    Loss: 1.287748098373413\n",
            "  Batch 1000  of  16875.    Loss: 0.936376690864563\n",
            "  Batch 1100  of  16875.    Loss: 1.1557626724243164\n",
            "  Batch 1200  of  16875.    Loss: 0.9169806241989136\n",
            "  Batch 1300  of  16875.    Loss: 1.0582611560821533\n",
            "  Batch 1400  of  16875.    Loss: 0.995667576789856\n",
            "  Batch 1500  of  16875.    Loss: 1.1234227418899536\n",
            "  Batch 1600  of  16875.    Loss: 1.2362499237060547\n",
            "  Batch 1700  of  16875.    Loss: 1.0362366437911987\n",
            "  Batch 1800  of  16875.    Loss: 0.9342665672302246\n",
            "  Batch 1900  of  16875.    Loss: 1.074463963508606\n",
            "  Batch 2000  of  16875.    Loss: 1.1266894340515137\n",
            "  Batch 2100  of  16875.    Loss: 1.1491551399230957\n",
            "  Batch 2200  of  16875.    Loss: 0.9350078701972961\n",
            "  Batch 2300  of  16875.    Loss: 0.9952136874198914\n",
            "  Batch 2400  of  16875.    Loss: 0.8932536840438843\n",
            "  Batch 2500  of  16875.    Loss: 1.0332386493682861\n",
            "  Batch 2600  of  16875.    Loss: 0.8922683596611023\n",
            "  Batch 2700  of  16875.    Loss: 0.7009317278862\n",
            "  Batch 2800  of  16875.    Loss: 1.031191349029541\n",
            "  Batch 2900  of  16875.    Loss: 1.1213105916976929\n",
            "  Batch 3000  of  16875.    Loss: 1.0134919881820679\n",
            "  Batch 3100  of  16875.    Loss: 1.013028621673584\n",
            "  Batch 3200  of  16875.    Loss: 1.201680302619934\n",
            "  Batch 3300  of  16875.    Loss: 1.1667029857635498\n",
            "  Batch 3400  of  16875.    Loss: 0.8909465670585632\n",
            "  Batch 3500  of  16875.    Loss: 0.8967539072036743\n",
            "  Batch 3600  of  16875.    Loss: 1.1994720697402954\n",
            "  Batch 3700  of  16875.    Loss: 1.011407494544983\n",
            "  Batch 3800  of  16875.    Loss: 1.0576684474945068\n",
            "  Batch 3900  of  16875.    Loss: 0.9303848147392273\n",
            "  Batch 4000  of  16875.    Loss: 0.9829138517379761\n",
            "  Batch 4100  of  16875.    Loss: 1.0585554838180542\n",
            "  Batch 4200  of  16875.    Loss: 0.9485456347465515\n",
            "  Batch 4300  of  16875.    Loss: 1.023958683013916\n",
            "  Batch 4400  of  16875.    Loss: 0.7100565433502197\n",
            "  Batch 4500  of  16875.    Loss: 0.9219197034835815\n",
            "  Batch 4600  of  16875.    Loss: 1.3030319213867188\n",
            "  Batch 4700  of  16875.    Loss: 1.0665591955184937\n",
            "  Batch 4800  of  16875.    Loss: 1.0703004598617554\n",
            "  Batch 4900  of  16875.    Loss: 0.9045859575271606\n",
            "  Batch 5000  of  16875.    Loss: 0.8372036218643188\n",
            "  Batch 5100  of  16875.    Loss: 0.9518308639526367\n",
            "  Batch 5200  of  16875.    Loss: 1.001939058303833\n",
            "  Batch 5300  of  16875.    Loss: 0.8938277363777161\n",
            "  Batch 5400  of  16875.    Loss: 1.162907600402832\n",
            "  Batch 5500  of  16875.    Loss: 0.8476777076721191\n",
            "  Batch 5600  of  16875.    Loss: 0.9747180938720703\n",
            "  Batch 5700  of  16875.    Loss: 1.049497127532959\n",
            "  Batch 5800  of  16875.    Loss: 0.8298705816268921\n",
            "  Batch 5900  of  16875.    Loss: 1.0225019454956055\n",
            "  Batch 6000  of  16875.    Loss: 1.0965595245361328\n",
            "  Batch 6100  of  16875.    Loss: 0.7488763332366943\n",
            "  Batch 6200  of  16875.    Loss: 1.1743314266204834\n",
            "  Batch 6300  of  16875.    Loss: 0.9355276823043823\n",
            "  Batch 6400  of  16875.    Loss: 0.9726686477661133\n",
            "  Batch 6500  of  16875.    Loss: 1.0354688167572021\n",
            "  Batch 6600  of  16875.    Loss: 0.9942922592163086\n",
            "  Batch 6700  of  16875.    Loss: 1.0070102214813232\n",
            "  Batch 6800  of  16875.    Loss: 1.0048027038574219\n",
            "  Batch 6900  of  16875.    Loss: 0.8687112927436829\n",
            "  Batch 7000  of  16875.    Loss: 0.731250524520874\n",
            "  Batch 7100  of  16875.    Loss: 0.8715893030166626\n",
            "  Batch 7200  of  16875.    Loss: 1.0547316074371338\n",
            "  Batch 7300  of  16875.    Loss: 1.097493052482605\n",
            "  Batch 7400  of  16875.    Loss: 0.9871069192886353\n",
            "  Batch 7500  of  16875.    Loss: 0.8033355474472046\n",
            "  Batch 7600  of  16875.    Loss: 1.05739426612854\n",
            "  Batch 7700  of  16875.    Loss: 0.9380565881729126\n",
            "  Batch 7800  of  16875.    Loss: 1.1041021347045898\n",
            "  Batch 7900  of  16875.    Loss: 0.9573181867599487\n",
            "  Batch 8000  of  16875.    Loss: 1.1015570163726807\n",
            "  Batch 8100  of  16875.    Loss: 1.1158932447433472\n",
            "  Batch 8200  of  16875.    Loss: 1.2916572093963623\n",
            "  Batch 8300  of  16875.    Loss: 0.8393489718437195\n",
            "  Batch 8400  of  16875.    Loss: 0.8939864039421082\n",
            "  Batch 8500  of  16875.    Loss: 0.982546329498291\n",
            "  Batch 8600  of  16875.    Loss: 1.1990383863449097\n",
            "  Batch 8700  of  16875.    Loss: 0.7517005205154419\n",
            "  Batch 8800  of  16875.    Loss: 0.8641373515129089\n",
            "  Batch 8900  of  16875.    Loss: 0.8391122817993164\n",
            "  Batch 9000  of  16875.    Loss: 0.7211006879806519\n",
            "  Batch 9100  of  16875.    Loss: 0.7876293659210205\n",
            "  Batch 9200  of  16875.    Loss: 0.9692195057868958\n",
            "  Batch 9300  of  16875.    Loss: 0.9244645237922668\n",
            "  Batch 9400  of  16875.    Loss: 0.8248670697212219\n",
            "  Batch 9500  of  16875.    Loss: 0.7409011125564575\n",
            "  Batch 9600  of  16875.    Loss: 0.8998345136642456\n",
            "  Batch 9700  of  16875.    Loss: 0.9205809831619263\n",
            "  Batch 9800  of  16875.    Loss: 0.8751112818717957\n",
            "  Batch 9900  of  16875.    Loss: 0.9570686221122742\n",
            "  Batch 10000  of  16875.    Loss: 0.9085216522216797\n",
            "  Batch 10100  of  16875.    Loss: 1.1066781282424927\n",
            "  Batch 10200  of  16875.    Loss: 1.0833380222320557\n",
            "  Batch 10300  of  16875.    Loss: 1.105534315109253\n",
            "  Batch 10400  of  16875.    Loss: 0.819011390209198\n",
            "  Batch 10500  of  16875.    Loss: 0.8216248750686646\n",
            "  Batch 10600  of  16875.    Loss: 1.045968770980835\n",
            "  Batch 10700  of  16875.    Loss: 0.8921748399734497\n",
            "  Batch 10800  of  16875.    Loss: 0.9025642275810242\n",
            "  Batch 10900  of  16875.    Loss: 0.9139032363891602\n",
            "  Batch 11000  of  16875.    Loss: 0.9728018045425415\n",
            "  Batch 11100  of  16875.    Loss: 0.9701142311096191\n",
            "  Batch 11200  of  16875.    Loss: 0.8398952484130859\n",
            "  Batch 11300  of  16875.    Loss: 0.7667682766914368\n",
            "  Batch 11400  of  16875.    Loss: 1.298191785812378\n",
            "  Batch 11500  of  16875.    Loss: 0.9749944806098938\n",
            "  Batch 11600  of  16875.    Loss: 0.937717080116272\n",
            "  Batch 11700  of  16875.    Loss: 1.0149732828140259\n",
            "  Batch 11800  of  16875.    Loss: 0.8475224375724792\n",
            "  Batch 11900  of  16875.    Loss: 0.7764220237731934\n",
            "  Batch 12000  of  16875.    Loss: 1.1133062839508057\n",
            "  Batch 12100  of  16875.    Loss: 0.8731521368026733\n",
            "  Batch 12200  of  16875.    Loss: 0.9362233281135559\n",
            "  Batch 12300  of  16875.    Loss: 0.8345807194709778\n",
            "  Batch 12400  of  16875.    Loss: 0.9346774220466614\n",
            "  Batch 12500  of  16875.    Loss: 0.7880926132202148\n",
            "  Batch 12600  of  16875.    Loss: 1.1848704814910889\n",
            "  Batch 12700  of  16875.    Loss: 0.9291433095932007\n",
            "  Batch 12800  of  16875.    Loss: 0.9265025854110718\n",
            "  Batch 12900  of  16875.    Loss: 1.19101881980896\n",
            "  Batch 13000  of  16875.    Loss: 0.9446109533309937\n",
            "  Batch 13100  of  16875.    Loss: 0.9256705045700073\n",
            "  Batch 13200  of  16875.    Loss: 0.7917283773422241\n",
            "  Batch 13300  of  16875.    Loss: 0.8959637880325317\n",
            "  Batch 13400  of  16875.    Loss: 0.8575517535209656\n",
            "  Batch 13500  of  16875.    Loss: 0.826555609703064\n",
            "  Batch 13600  of  16875.    Loss: 1.1870378255844116\n",
            "  Batch 13700  of  16875.    Loss: 0.8470800518989563\n",
            "  Batch 13800  of  16875.    Loss: 0.9042302966117859\n",
            "  Batch 13900  of  16875.    Loss: 0.8683387637138367\n",
            "  Batch 14000  of  16875.    Loss: 0.9985470771789551\n",
            "  Batch 14100  of  16875.    Loss: 0.7527144551277161\n",
            "  Batch 14200  of  16875.    Loss: 0.774946391582489\n",
            "  Batch 14300  of  16875.    Loss: 0.7063091397285461\n",
            "  Batch 14400  of  16875.    Loss: 0.8022303581237793\n",
            "  Batch 14500  of  16875.    Loss: 0.8790603876113892\n",
            "  Batch 14600  of  16875.    Loss: 0.854571521282196\n",
            "  Batch 14700  of  16875.    Loss: 0.8142792582511902\n",
            "  Batch 14800  of  16875.    Loss: 0.8773766756057739\n",
            "  Batch 14900  of  16875.    Loss: 1.0028082132339478\n",
            "  Batch 15000  of  16875.    Loss: 0.8424291610717773\n",
            "  Batch 15100  of  16875.    Loss: 0.8400925397872925\n",
            "  Batch 15200  of  16875.    Loss: 0.7949482202529907\n",
            "  Batch 15300  of  16875.    Loss: 0.5688235759735107\n",
            "  Batch 15400  of  16875.    Loss: 0.9407650828361511\n",
            "  Batch 15500  of  16875.    Loss: 1.2399990558624268\n",
            "  Batch 15600  of  16875.    Loss: 0.9052456021308899\n",
            "  Batch 15700  of  16875.    Loss: 0.8121922612190247\n",
            "  Batch 15800  of  16875.    Loss: 0.7932485342025757\n",
            "  Batch 15900  of  16875.    Loss: 0.999305248260498\n",
            "  Batch 16000  of  16875.    Loss: 0.8125377893447876\n",
            "  Batch 16100  of  16875.    Loss: 0.651544451713562\n",
            "  Batch 16200  of  16875.    Loss: 0.8968302011489868\n",
            "  Batch 16300  of  16875.    Loss: 0.8363518714904785\n",
            "  Batch 16400  of  16875.    Loss: 0.663737952709198\n",
            "  Batch 16500  of  16875.    Loss: 0.8347930908203125\n",
            "  Batch 16600  of  16875.    Loss: 0.8806754350662231\n",
            "  Batch 16700  of  16875.    Loss: 0.9446288347244263\n",
            "  Batch 16800  of  16875.    Loss: 0.7783899307250977\n",
            "Average training loss: 0.9478348547423328\n",
            "Epoch 3/5\n",
            "----------\n",
            "  Batch 100  of  16875.    Loss: 0.7467743158340454\n",
            "  Batch 200  of  16875.    Loss: 0.7737525105476379\n",
            "  Batch 300  of  16875.    Loss: 0.8149965405464172\n",
            "  Batch 400  of  16875.    Loss: 0.7620211839675903\n",
            "  Batch 500  of  16875.    Loss: 0.7288414239883423\n",
            "  Batch 600  of  16875.    Loss: 0.8468042612075806\n",
            "  Batch 700  of  16875.    Loss: 0.6579813361167908\n",
            "  Batch 800  of  16875.    Loss: 0.641846239566803\n",
            "  Batch 900  of  16875.    Loss: 0.8136944770812988\n",
            "  Batch 1000  of  16875.    Loss: 0.685431182384491\n",
            "  Batch 1100  of  16875.    Loss: 0.6853843927383423\n",
            "  Batch 1200  of  16875.    Loss: 0.8493896722793579\n",
            "  Batch 1300  of  16875.    Loss: 1.0619345903396606\n",
            "  Batch 1400  of  16875.    Loss: 1.2645207643508911\n",
            "  Batch 1500  of  16875.    Loss: 0.8105743527412415\n",
            "  Batch 1600  of  16875.    Loss: 0.7980535626411438\n",
            "  Batch 1700  of  16875.    Loss: 1.1179721355438232\n",
            "  Batch 1800  of  16875.    Loss: 0.5650792717933655\n",
            "  Batch 1900  of  16875.    Loss: 0.746268630027771\n",
            "  Batch 2000  of  16875.    Loss: 0.6763125658035278\n",
            "  Batch 2100  of  16875.    Loss: 0.7470191717147827\n",
            "  Batch 2200  of  16875.    Loss: 0.8307570219039917\n",
            "  Batch 2300  of  16875.    Loss: 0.7727362513542175\n",
            "  Batch 2400  of  16875.    Loss: 0.8839318156242371\n",
            "  Batch 2500  of  16875.    Loss: 0.7991718649864197\n",
            "  Batch 2600  of  16875.    Loss: 0.5226548314094543\n",
            "  Batch 2700  of  16875.    Loss: 0.7429074645042419\n",
            "  Batch 2800  of  16875.    Loss: 0.8841035962104797\n",
            "  Batch 2900  of  16875.    Loss: 0.8118893504142761\n",
            "  Batch 3000  of  16875.    Loss: 0.8539025187492371\n",
            "  Batch 3100  of  16875.    Loss: 0.7722756266593933\n",
            "  Batch 3200  of  16875.    Loss: 0.6410374641418457\n",
            "  Batch 3300  of  16875.    Loss: 0.760647177696228\n",
            "  Batch 3400  of  16875.    Loss: 0.7737241983413696\n",
            "  Batch 3500  of  16875.    Loss: 1.0882216691970825\n",
            "  Batch 3600  of  16875.    Loss: 0.8142117261886597\n",
            "  Batch 3700  of  16875.    Loss: 0.8512929081916809\n",
            "  Batch 3800  of  16875.    Loss: 0.8998165130615234\n",
            "  Batch 3900  of  16875.    Loss: 0.5878122448921204\n",
            "  Batch 4000  of  16875.    Loss: 0.8424739837646484\n",
            "  Batch 4100  of  16875.    Loss: 0.7931419610977173\n",
            "  Batch 4200  of  16875.    Loss: 0.788273811340332\n",
            "  Batch 4300  of  16875.    Loss: 0.6239252686500549\n",
            "  Batch 4400  of  16875.    Loss: 0.6895964741706848\n",
            "  Batch 4500  of  16875.    Loss: 0.7002715468406677\n",
            "  Batch 4600  of  16875.    Loss: 0.7432206869125366\n",
            "  Batch 4700  of  16875.    Loss: 0.7889676690101624\n",
            "  Batch 4800  of  16875.    Loss: 0.8322811126708984\n",
            "  Batch 4900  of  16875.    Loss: 0.7608844637870789\n",
            "  Batch 5000  of  16875.    Loss: 0.959189772605896\n",
            "  Batch 5100  of  16875.    Loss: 0.7974112033843994\n",
            "  Batch 5200  of  16875.    Loss: 0.5299769639968872\n",
            "  Batch 5300  of  16875.    Loss: 0.6860666871070862\n",
            "  Batch 5400  of  16875.    Loss: 0.8597128987312317\n",
            "  Batch 5500  of  16875.    Loss: 0.748760998249054\n",
            "  Batch 5600  of  16875.    Loss: 1.0799267292022705\n",
            "  Batch 5700  of  16875.    Loss: 1.0341286659240723\n",
            "  Batch 5800  of  16875.    Loss: 0.8083144426345825\n",
            "  Batch 5900  of  16875.    Loss: 0.7685410380363464\n",
            "  Batch 6000  of  16875.    Loss: 0.7094259262084961\n",
            "  Batch 6100  of  16875.    Loss: 0.9264482259750366\n",
            "  Batch 6200  of  16875.    Loss: 0.8696306347846985\n",
            "  Batch 6300  of  16875.    Loss: 0.9257462620735168\n",
            "  Batch 6400  of  16875.    Loss: 0.8425660133361816\n",
            "  Batch 6500  of  16875.    Loss: 0.7028194069862366\n",
            "  Batch 6600  of  16875.    Loss: 0.6158546209335327\n",
            "  Batch 6700  of  16875.    Loss: 0.6430265307426453\n",
            "  Batch 6800  of  16875.    Loss: 0.895912766456604\n",
            "  Batch 6900  of  16875.    Loss: 0.5892455577850342\n",
            "  Batch 7000  of  16875.    Loss: 0.723641037940979\n",
            "  Batch 7100  of  16875.    Loss: 0.7705565690994263\n",
            "  Batch 7200  of  16875.    Loss: 1.0027306079864502\n",
            "  Batch 7300  of  16875.    Loss: 0.6445516347885132\n",
            "  Batch 7400  of  16875.    Loss: 0.6887456178665161\n",
            "  Batch 7500  of  16875.    Loss: 0.5972567796707153\n",
            "  Batch 7600  of  16875.    Loss: 0.7346997261047363\n",
            "  Batch 7700  of  16875.    Loss: 0.6227718591690063\n",
            "  Batch 7800  of  16875.    Loss: 0.8323149681091309\n",
            "  Batch 7900  of  16875.    Loss: 0.9190999865531921\n",
            "  Batch 8000  of  16875.    Loss: 0.6085759401321411\n",
            "  Batch 8100  of  16875.    Loss: 0.7566102147102356\n",
            "  Batch 8200  of  16875.    Loss: 0.7879514098167419\n",
            "  Batch 8300  of  16875.    Loss: 0.7263545989990234\n",
            "  Batch 8400  of  16875.    Loss: 0.7983259558677673\n",
            "  Batch 8500  of  16875.    Loss: 0.7317456007003784\n",
            "  Batch 8600  of  16875.    Loss: 0.7236307263374329\n",
            "  Batch 8700  of  16875.    Loss: 0.6729574203491211\n",
            "  Batch 8800  of  16875.    Loss: 0.6192771792411804\n",
            "  Batch 8900  of  16875.    Loss: 0.9522351026535034\n",
            "  Batch 9000  of  16875.    Loss: 0.6468900442123413\n",
            "  Batch 9100  of  16875.    Loss: 0.8505946397781372\n",
            "  Batch 9200  of  16875.    Loss: 0.5978301167488098\n",
            "  Batch 9300  of  16875.    Loss: 0.5898041725158691\n",
            "  Batch 9400  of  16875.    Loss: 0.8481895327568054\n",
            "  Batch 9500  of  16875.    Loss: 0.7859968543052673\n",
            "  Batch 9600  of  16875.    Loss: 0.6902510523796082\n",
            "  Batch 9700  of  16875.    Loss: 0.8365172147750854\n",
            "  Batch 9800  of  16875.    Loss: 0.7007677555084229\n",
            "  Batch 9900  of  16875.    Loss: 0.9188743829727173\n",
            "  Batch 10000  of  16875.    Loss: 0.8313446044921875\n",
            "  Batch 10100  of  16875.    Loss: 0.9802830815315247\n",
            "  Batch 10200  of  16875.    Loss: 0.8693333864212036\n",
            "  Batch 10300  of  16875.    Loss: 0.8259965777397156\n",
            "  Batch 10400  of  16875.    Loss: 0.9474563598632812\n",
            "  Batch 10500  of  16875.    Loss: 0.5981850624084473\n",
            "  Batch 10600  of  16875.    Loss: 0.9950389862060547\n",
            "  Batch 10700  of  16875.    Loss: 0.7414937615394592\n",
            "  Batch 10800  of  16875.    Loss: 0.8020659685134888\n",
            "  Batch 10900  of  16875.    Loss: 0.7322860956192017\n",
            "  Batch 11000  of  16875.    Loss: 0.8499302864074707\n",
            "  Batch 11100  of  16875.    Loss: 0.8789680600166321\n",
            "  Batch 11200  of  16875.    Loss: 0.6770258545875549\n",
            "  Batch 11300  of  16875.    Loss: 0.8181397318840027\n",
            "  Batch 11400  of  16875.    Loss: 0.6547326445579529\n",
            "  Batch 11500  of  16875.    Loss: 0.6691867709159851\n",
            "  Batch 11600  of  16875.    Loss: 0.7337695360183716\n",
            "  Batch 11700  of  16875.    Loss: 0.8362134099006653\n",
            "  Batch 11800  of  16875.    Loss: 0.6048572659492493\n",
            "  Batch 11900  of  16875.    Loss: 0.6757887601852417\n",
            "  Batch 12000  of  16875.    Loss: 0.8362808227539062\n",
            "  Batch 12100  of  16875.    Loss: 0.6867578625679016\n",
            "  Batch 12200  of  16875.    Loss: 0.6869574785232544\n",
            "  Batch 12300  of  16875.    Loss: 0.6013502478599548\n",
            "  Batch 12400  of  16875.    Loss: 0.7369948029518127\n",
            "  Batch 12500  of  16875.    Loss: 0.7777758836746216\n",
            "  Batch 12600  of  16875.    Loss: 0.5231760740280151\n",
            "  Batch 12700  of  16875.    Loss: 0.8037617802619934\n",
            "  Batch 12800  of  16875.    Loss: 0.6154570579528809\n",
            "  Batch 12900  of  16875.    Loss: 0.6549261808395386\n",
            "  Batch 13000  of  16875.    Loss: 0.7446916699409485\n",
            "  Batch 13100  of  16875.    Loss: 0.6063576936721802\n",
            "  Batch 13200  of  16875.    Loss: 0.7011892795562744\n",
            "  Batch 13300  of  16875.    Loss: 0.6662436127662659\n",
            "  Batch 13400  of  16875.    Loss: 0.6679468154907227\n",
            "  Batch 13500  of  16875.    Loss: 0.712500274181366\n",
            "  Batch 13600  of  16875.    Loss: 0.7042562365531921\n",
            "  Batch 13700  of  16875.    Loss: 0.8804747462272644\n",
            "  Batch 13800  of  16875.    Loss: 0.8285388946533203\n",
            "  Batch 13900  of  16875.    Loss: 0.624500036239624\n",
            "  Batch 14000  of  16875.    Loss: 0.9175499677658081\n",
            "  Batch 14100  of  16875.    Loss: 0.8019533157348633\n",
            "  Batch 14200  of  16875.    Loss: 0.8699185252189636\n",
            "  Batch 14300  of  16875.    Loss: 0.6208935976028442\n",
            "  Batch 14400  of  16875.    Loss: 0.587754487991333\n",
            "  Batch 14500  of  16875.    Loss: 0.5441630482673645\n",
            "  Batch 14600  of  16875.    Loss: 0.8006553649902344\n",
            "  Batch 14700  of  16875.    Loss: 0.6111465692520142\n",
            "  Batch 14800  of  16875.    Loss: 0.7477238774299622\n",
            "  Batch 14900  of  16875.    Loss: 0.6549268364906311\n",
            "  Batch 15000  of  16875.    Loss: 0.5602892637252808\n",
            "  Batch 15100  of  16875.    Loss: 0.8054474592208862\n",
            "  Batch 15200  of  16875.    Loss: 0.9253052473068237\n",
            "  Batch 15300  of  16875.    Loss: 0.638674259185791\n",
            "  Batch 15400  of  16875.    Loss: 0.5386724472045898\n",
            "  Batch 15500  of  16875.    Loss: 0.8715808987617493\n",
            "  Batch 15600  of  16875.    Loss: 0.8988510370254517\n",
            "  Batch 15700  of  16875.    Loss: 0.8030600547790527\n",
            "  Batch 15800  of  16875.    Loss: 0.6655822992324829\n",
            "  Batch 15900  of  16875.    Loss: 0.7852766513824463\n",
            "  Batch 16000  of  16875.    Loss: 0.7543350458145142\n",
            "  Batch 16100  of  16875.    Loss: 0.7943947315216064\n",
            "  Batch 16200  of  16875.    Loss: 0.492229163646698\n",
            "  Batch 16300  of  16875.    Loss: 0.6957836747169495\n",
            "  Batch 16400  of  16875.    Loss: 0.819574236869812\n",
            "  Batch 16500  of  16875.    Loss: 0.7167128324508667\n",
            "  Batch 16600  of  16875.    Loss: 0.9380956888198853\n",
            "  Batch 16700  of  16875.    Loss: 0.7214147448539734\n",
            "  Batch 16800  of  16875.    Loss: 0.6002171635627747\n",
            "Average training loss: 0.7765391522990333\n",
            "Epoch 4/5\n",
            "----------\n",
            "  Batch 100  of  16875.    Loss: 0.5745922327041626\n",
            "  Batch 200  of  16875.    Loss: 0.9498023986816406\n",
            "  Batch 300  of  16875.    Loss: 0.6471412777900696\n",
            "  Batch 400  of  16875.    Loss: 0.8923300504684448\n",
            "  Batch 500  of  16875.    Loss: 0.5287503004074097\n",
            "  Batch 600  of  16875.    Loss: 0.7556325197219849\n",
            "  Batch 700  of  16875.    Loss: 0.8438042402267456\n",
            "  Batch 800  of  16875.    Loss: 0.7961477041244507\n",
            "  Batch 900  of  16875.    Loss: 0.603259801864624\n",
            "  Batch 1000  of  16875.    Loss: 0.8105807304382324\n",
            "  Batch 1100  of  16875.    Loss: 0.4790183901786804\n",
            "  Batch 1200  of  16875.    Loss: 0.9264564514160156\n",
            "  Batch 1300  of  16875.    Loss: 0.7352430820465088\n",
            "  Batch 1400  of  16875.    Loss: 0.6104671955108643\n",
            "  Batch 1500  of  16875.    Loss: 0.8286843299865723\n",
            "  Batch 1600  of  16875.    Loss: 0.6976563334465027\n",
            "  Batch 1700  of  16875.    Loss: 0.5978630185127258\n",
            "  Batch 1800  of  16875.    Loss: 0.7413520812988281\n",
            "  Batch 1900  of  16875.    Loss: 0.7433411478996277\n",
            "  Batch 2000  of  16875.    Loss: 0.5975056886672974\n",
            "  Batch 2100  of  16875.    Loss: 0.7283790707588196\n",
            "  Batch 2200  of  16875.    Loss: 0.6363893747329712\n",
            "  Batch 2300  of  16875.    Loss: 0.7365628480911255\n",
            "  Batch 2400  of  16875.    Loss: 0.7787541747093201\n",
            "  Batch 2500  of  16875.    Loss: 0.7838094830513\n",
            "  Batch 2600  of  16875.    Loss: 0.6206324696540833\n",
            "  Batch 2700  of  16875.    Loss: 0.7632299065589905\n",
            "  Batch 2800  of  16875.    Loss: 0.8258639574050903\n",
            "  Batch 2900  of  16875.    Loss: 0.6671690940856934\n",
            "  Batch 3000  of  16875.    Loss: 0.7306669354438782\n",
            "  Batch 3100  of  16875.    Loss: 0.6737542748451233\n",
            "  Batch 3200  of  16875.    Loss: 0.6514472961425781\n",
            "  Batch 3300  of  16875.    Loss: 0.7754027247428894\n",
            "  Batch 3400  of  16875.    Loss: 0.7028979659080505\n",
            "  Batch 3500  of  16875.    Loss: 0.6965791583061218\n",
            "  Batch 3600  of  16875.    Loss: 0.6109895706176758\n",
            "  Batch 3700  of  16875.    Loss: 0.85411536693573\n",
            "  Batch 3800  of  16875.    Loss: 0.6585999727249146\n",
            "  Batch 3900  of  16875.    Loss: 0.7003014087677002\n",
            "  Batch 4000  of  16875.    Loss: 0.9924931526184082\n",
            "  Batch 4100  of  16875.    Loss: 0.701493501663208\n",
            "  Batch 4200  of  16875.    Loss: 0.7176440358161926\n",
            "  Batch 4300  of  16875.    Loss: 0.6268740892410278\n",
            "  Batch 4400  of  16875.    Loss: 0.4820840358734131\n",
            "  Batch 4500  of  16875.    Loss: 0.682685911655426\n",
            "  Batch 4600  of  16875.    Loss: 0.5857341289520264\n",
            "  Batch 4700  of  16875.    Loss: 0.6688228845596313\n",
            "  Batch 4800  of  16875.    Loss: 0.726995050907135\n",
            "  Batch 4900  of  16875.    Loss: 0.7696425318717957\n",
            "  Batch 5000  of  16875.    Loss: 0.7510064840316772\n",
            "  Batch 5100  of  16875.    Loss: 0.8105906248092651\n",
            "  Batch 5200  of  16875.    Loss: 0.6125260591506958\n",
            "  Batch 5300  of  16875.    Loss: 0.6936581134796143\n",
            "  Batch 5400  of  16875.    Loss: 0.7861994504928589\n",
            "  Batch 5500  of  16875.    Loss: 0.7440242767333984\n",
            "  Batch 5600  of  16875.    Loss: 0.9729498028755188\n",
            "  Batch 5700  of  16875.    Loss: 0.6474109888076782\n",
            "  Batch 5800  of  16875.    Loss: 0.6277232766151428\n",
            "  Batch 5900  of  16875.    Loss: 0.6395655870437622\n",
            "  Batch 6000  of  16875.    Loss: 0.7025830149650574\n",
            "  Batch 6100  of  16875.    Loss: 0.5788507461547852\n",
            "  Batch 6200  of  16875.    Loss: 0.8016673922538757\n",
            "  Batch 6300  of  16875.    Loss: 0.6868634223937988\n",
            "  Batch 6400  of  16875.    Loss: 0.8197660446166992\n",
            "  Batch 6500  of  16875.    Loss: 0.5469046235084534\n",
            "  Batch 6600  of  16875.    Loss: 0.6663707494735718\n",
            "  Batch 6700  of  16875.    Loss: 0.7178031206130981\n",
            "  Batch 6800  of  16875.    Loss: 0.7094376683235168\n",
            "  Batch 6900  of  16875.    Loss: 0.8650625944137573\n",
            "  Batch 7000  of  16875.    Loss: 0.5513116121292114\n",
            "  Batch 7100  of  16875.    Loss: 0.680505096912384\n",
            "  Batch 7200  of  16875.    Loss: 0.8684232831001282\n",
            "  Batch 7300  of  16875.    Loss: 0.5910124778747559\n",
            "  Batch 7400  of  16875.    Loss: 0.7836015820503235\n",
            "  Batch 7500  of  16875.    Loss: 0.652637779712677\n",
            "  Batch 7600  of  16875.    Loss: 0.6815099716186523\n",
            "  Batch 7700  of  16875.    Loss: 0.41179436445236206\n",
            "  Batch 7800  of  16875.    Loss: 0.7321252226829529\n",
            "  Batch 7900  of  16875.    Loss: 0.650001049041748\n",
            "  Batch 8000  of  16875.    Loss: 0.808050811290741\n",
            "  Batch 8100  of  16875.    Loss: 0.644452691078186\n",
            "  Batch 8200  of  16875.    Loss: 0.6411525011062622\n",
            "  Batch 8300  of  16875.    Loss: 0.6021589040756226\n",
            "  Batch 8400  of  16875.    Loss: 0.6863247156143188\n",
            "  Batch 8500  of  16875.    Loss: 0.4586906433105469\n",
            "  Batch 8600  of  16875.    Loss: 0.7036503553390503\n",
            "  Batch 8700  of  16875.    Loss: 0.71605384349823\n",
            "  Batch 8800  of  16875.    Loss: 0.7652897834777832\n",
            "  Batch 8900  of  16875.    Loss: 0.8706925511360168\n",
            "  Batch 9000  of  16875.    Loss: 0.6586483716964722\n",
            "  Batch 9100  of  16875.    Loss: 0.5788834691047668\n",
            "  Batch 9200  of  16875.    Loss: 0.8771806955337524\n",
            "  Batch 9300  of  16875.    Loss: 0.5924503207206726\n",
            "  Batch 9400  of  16875.    Loss: 0.5204671025276184\n",
            "  Batch 9500  of  16875.    Loss: 0.5787075757980347\n",
            "  Batch 9600  of  16875.    Loss: 0.6315604448318481\n",
            "  Batch 9700  of  16875.    Loss: 0.5885072350502014\n",
            "  Batch 9800  of  16875.    Loss: 0.734517514705658\n",
            "  Batch 9900  of  16875.    Loss: 0.7255473136901855\n",
            "  Batch 10000  of  16875.    Loss: 0.5744457244873047\n",
            "  Batch 10100  of  16875.    Loss: 0.5843597650527954\n",
            "  Batch 10200  of  16875.    Loss: 0.6398431062698364\n",
            "  Batch 10300  of  16875.    Loss: 0.6941250562667847\n",
            "  Batch 10400  of  16875.    Loss: 0.7543907761573792\n",
            "  Batch 10500  of  16875.    Loss: 0.4693361818790436\n",
            "  Batch 10600  of  16875.    Loss: 0.7968870401382446\n",
            "  Batch 10700  of  16875.    Loss: 0.7315700650215149\n",
            "  Batch 10800  of  16875.    Loss: 0.614861011505127\n",
            "  Batch 10900  of  16875.    Loss: 0.698233962059021\n",
            "  Batch 11000  of  16875.    Loss: 0.5975722074508667\n",
            "  Batch 11100  of  16875.    Loss: 0.7657608389854431\n",
            "  Batch 11200  of  16875.    Loss: 0.6392172574996948\n",
            "  Batch 11300  of  16875.    Loss: 0.7531677484512329\n",
            "  Batch 11400  of  16875.    Loss: 0.5307196974754333\n",
            "  Batch 11500  of  16875.    Loss: 0.6653755903244019\n",
            "  Batch 11600  of  16875.    Loss: 0.8051127195358276\n",
            "  Batch 11700  of  16875.    Loss: 0.7879670262336731\n",
            "  Batch 11800  of  16875.    Loss: 0.7080132365226746\n",
            "  Batch 11900  of  16875.    Loss: 0.45893630385398865\n",
            "  Batch 12000  of  16875.    Loss: 0.8463883399963379\n",
            "  Batch 12100  of  16875.    Loss: 0.7199752926826477\n",
            "  Batch 12200  of  16875.    Loss: 0.6275322437286377\n",
            "  Batch 12300  of  16875.    Loss: 0.6819747686386108\n",
            "  Batch 12400  of  16875.    Loss: 0.5542522668838501\n",
            "  Batch 12500  of  16875.    Loss: 0.5160799026489258\n",
            "  Batch 12600  of  16875.    Loss: 0.7680422067642212\n",
            "  Batch 12700  of  16875.    Loss: 0.6483058333396912\n",
            "  Batch 12800  of  16875.    Loss: 0.6964552402496338\n",
            "  Batch 12900  of  16875.    Loss: 0.8982362747192383\n",
            "  Batch 13000  of  16875.    Loss: 0.8208701014518738\n",
            "  Batch 13100  of  16875.    Loss: 0.6589567065238953\n",
            "  Batch 13200  of  16875.    Loss: 0.641656756401062\n",
            "  Batch 13300  of  16875.    Loss: 0.8329412341117859\n",
            "  Batch 13400  of  16875.    Loss: 0.5952345132827759\n",
            "  Batch 13500  of  16875.    Loss: 0.6336950659751892\n",
            "  Batch 13600  of  16875.    Loss: 0.5044006109237671\n",
            "  Batch 13700  of  16875.    Loss: 0.7037380337715149\n",
            "  Batch 13800  of  16875.    Loss: 0.7248808145523071\n",
            "  Batch 13900  of  16875.    Loss: 0.6209454536437988\n",
            "  Batch 14000  of  16875.    Loss: 0.5517314672470093\n",
            "  Batch 14100  of  16875.    Loss: 0.8789122700691223\n",
            "  Batch 14200  of  16875.    Loss: 0.5661240816116333\n",
            "  Batch 14300  of  16875.    Loss: 0.7223235368728638\n",
            "  Batch 14400  of  16875.    Loss: 0.5072286128997803\n",
            "  Batch 14500  of  16875.    Loss: 0.7369387149810791\n",
            "  Batch 14600  of  16875.    Loss: 0.8121060132980347\n",
            "  Batch 14700  of  16875.    Loss: 0.5912066698074341\n",
            "  Batch 14800  of  16875.    Loss: 0.8698687553405762\n",
            "  Batch 14900  of  16875.    Loss: 0.8712523579597473\n",
            "  Batch 15000  of  16875.    Loss: 0.6361920237541199\n",
            "  Batch 15100  of  16875.    Loss: 0.7827204465866089\n",
            "  Batch 15200  of  16875.    Loss: 0.7641332745552063\n",
            "  Batch 15300  of  16875.    Loss: 0.9427996873855591\n",
            "  Batch 15400  of  16875.    Loss: 0.8009177446365356\n",
            "  Batch 15500  of  16875.    Loss: 0.7094297409057617\n",
            "  Batch 15600  of  16875.    Loss: 0.8288253545761108\n",
            "  Batch 15700  of  16875.    Loss: 0.6053839325904846\n",
            "  Batch 15800  of  16875.    Loss: 0.6553246974945068\n",
            "  Batch 15900  of  16875.    Loss: 0.4056394696235657\n",
            "  Batch 16000  of  16875.    Loss: 0.8729053735733032\n",
            "  Batch 16100  of  16875.    Loss: 0.5195254683494568\n",
            "  Batch 16200  of  16875.    Loss: 0.5597807168960571\n",
            "  Batch 16300  of  16875.    Loss: 0.8222954869270325\n",
            "  Batch 16400  of  16875.    Loss: 0.5976614356040955\n",
            "  Batch 16500  of  16875.    Loss: 0.6762303113937378\n",
            "  Batch 16600  of  16875.    Loss: 0.6075947284698486\n",
            "  Batch 16700  of  16875.    Loss: 0.7310735583305359\n",
            "  Batch 16800  of  16875.    Loss: 0.6000779271125793\n",
            "Average training loss: 0.6885347526550293\n",
            "Epoch 5/5\n",
            "----------\n",
            "  Batch 100  of  16875.    Loss: 0.6719483137130737\n",
            "  Batch 200  of  16875.    Loss: 0.7464303374290466\n",
            "  Batch 300  of  16875.    Loss: 0.6068590879440308\n",
            "  Batch 400  of  16875.    Loss: 0.6852412819862366\n",
            "  Batch 500  of  16875.    Loss: 0.5386373996734619\n",
            "  Batch 600  of  16875.    Loss: 0.6948766708374023\n",
            "  Batch 700  of  16875.    Loss: 0.5333472490310669\n",
            "  Batch 800  of  16875.    Loss: 0.5880008935928345\n",
            "  Batch 900  of  16875.    Loss: 0.6495574712753296\n",
            "  Batch 1000  of  16875.    Loss: 0.6217532753944397\n",
            "  Batch 1100  of  16875.    Loss: 0.6389075517654419\n",
            "  Batch 1200  of  16875.    Loss: 0.7245816588401794\n",
            "  Batch 1300  of  16875.    Loss: 0.6284022927284241\n",
            "  Batch 1400  of  16875.    Loss: 0.6737431287765503\n",
            "  Batch 1500  of  16875.    Loss: 0.6492877006530762\n",
            "  Batch 1600  of  16875.    Loss: 0.5839528441429138\n",
            "  Batch 1700  of  16875.    Loss: 0.7403231859207153\n",
            "  Batch 1800  of  16875.    Loss: 0.7641273736953735\n",
            "  Batch 1900  of  16875.    Loss: 0.832050621509552\n",
            "  Batch 2000  of  16875.    Loss: 0.6692649126052856\n",
            "  Batch 2100  of  16875.    Loss: 0.6893699765205383\n",
            "  Batch 2200  of  16875.    Loss: 0.6643742322921753\n",
            "  Batch 2300  of  16875.    Loss: 0.6222285032272339\n",
            "  Batch 2400  of  16875.    Loss: 0.7295851707458496\n",
            "  Batch 2500  of  16875.    Loss: 0.5570660829544067\n",
            "  Batch 2600  of  16875.    Loss: 0.7069858312606812\n",
            "  Batch 2700  of  16875.    Loss: 0.6380331516265869\n",
            "  Batch 2800  of  16875.    Loss: 0.6046205759048462\n",
            "  Batch 2900  of  16875.    Loss: 0.5584220290184021\n",
            "  Batch 3000  of  16875.    Loss: 0.6294142603874207\n",
            "  Batch 3100  of  16875.    Loss: 0.6807019114494324\n",
            "  Batch 3200  of  16875.    Loss: 0.7721854448318481\n",
            "  Batch 3300  of  16875.    Loss: 0.5744442343711853\n",
            "  Batch 3400  of  16875.    Loss: 0.6666842699050903\n",
            "  Batch 3500  of  16875.    Loss: 0.5619813799858093\n",
            "  Batch 3600  of  16875.    Loss: 0.5755721926689148\n",
            "  Batch 3700  of  16875.    Loss: 0.6234296560287476\n",
            "  Batch 3800  of  16875.    Loss: 0.6876370310783386\n",
            "  Batch 3900  of  16875.    Loss: 0.6376665830612183\n",
            "  Batch 4000  of  16875.    Loss: 0.7152227163314819\n",
            "  Batch 4100  of  16875.    Loss: 0.6538270711898804\n",
            "  Batch 4200  of  16875.    Loss: 0.742127537727356\n",
            "  Batch 4300  of  16875.    Loss: 0.6625675559043884\n",
            "  Batch 4400  of  16875.    Loss: 0.5054608583450317\n",
            "  Batch 4500  of  16875.    Loss: 0.6877601742744446\n",
            "  Batch 4600  of  16875.    Loss: 0.7763229608535767\n",
            "  Batch 4700  of  16875.    Loss: 0.6696642637252808\n",
            "  Batch 4800  of  16875.    Loss: 0.6156812906265259\n",
            "  Batch 4900  of  16875.    Loss: 0.6347107291221619\n",
            "  Batch 5000  of  16875.    Loss: 0.6790590882301331\n",
            "  Batch 5100  of  16875.    Loss: 0.597769021987915\n",
            "  Batch 5200  of  16875.    Loss: 0.5639886260032654\n",
            "  Batch 5300  of  16875.    Loss: 0.6883605718612671\n",
            "  Batch 5400  of  16875.    Loss: 0.6173760294914246\n",
            "  Batch 5500  of  16875.    Loss: 0.7771796584129333\n",
            "  Batch 5600  of  16875.    Loss: 0.40990716218948364\n",
            "  Batch 5700  of  16875.    Loss: 0.6201509237289429\n",
            "  Batch 5800  of  16875.    Loss: 0.7572960257530212\n",
            "  Batch 5900  of  16875.    Loss: 0.5900604128837585\n",
            "  Batch 6000  of  16875.    Loss: 0.5450228452682495\n",
            "  Batch 6100  of  16875.    Loss: 0.7078155279159546\n",
            "  Batch 6200  of  16875.    Loss: 0.5181649327278137\n",
            "  Batch 6300  of  16875.    Loss: 0.5803722143173218\n",
            "  Batch 6400  of  16875.    Loss: 0.63849276304245\n",
            "  Batch 6500  of  16875.    Loss: 0.469238817691803\n",
            "  Batch 6600  of  16875.    Loss: 0.6761282682418823\n",
            "  Batch 6700  of  16875.    Loss: 0.6095524430274963\n",
            "  Batch 6800  of  16875.    Loss: 0.8720133900642395\n",
            "  Batch 6900  of  16875.    Loss: 0.4472436010837555\n",
            "  Batch 7000  of  16875.    Loss: 0.6729094982147217\n",
            "  Batch 7100  of  16875.    Loss: 0.8276259303092957\n",
            "  Batch 7200  of  16875.    Loss: 0.6268115639686584\n",
            "  Batch 7300  of  16875.    Loss: 0.8993356823921204\n",
            "  Batch 7400  of  16875.    Loss: 0.5160984992980957\n",
            "  Batch 7500  of  16875.    Loss: 0.7420212030410767\n",
            "  Batch 7600  of  16875.    Loss: 0.6754066944122314\n",
            "  Batch 7700  of  16875.    Loss: 0.45958787202835083\n",
            "  Batch 7800  of  16875.    Loss: 0.5448102355003357\n",
            "  Batch 7900  of  16875.    Loss: 0.8673806190490723\n",
            "  Batch 8000  of  16875.    Loss: 0.4926627278327942\n",
            "  Batch 8100  of  16875.    Loss: 0.5825926661491394\n",
            "  Batch 8200  of  16875.    Loss: 0.5697077512741089\n",
            "  Batch 8300  of  16875.    Loss: 0.9354749917984009\n",
            "  Batch 8400  of  16875.    Loss: 0.5022175312042236\n",
            "  Batch 8500  of  16875.    Loss: 0.5363152623176575\n",
            "  Batch 8600  of  16875.    Loss: 0.690405547618866\n",
            "  Batch 8700  of  16875.    Loss: 0.6889947056770325\n",
            "  Batch 8800  of  16875.    Loss: 0.689769983291626\n",
            "  Batch 8900  of  16875.    Loss: 0.6479527950286865\n",
            "  Batch 9000  of  16875.    Loss: 0.5312563180923462\n",
            "  Batch 9100  of  16875.    Loss: 0.6340423822402954\n",
            "  Batch 9200  of  16875.    Loss: 0.8721619844436646\n",
            "  Batch 9300  of  16875.    Loss: 0.6502620577812195\n",
            "  Batch 9400  of  16875.    Loss: 0.689895749092102\n",
            "  Batch 9500  of  16875.    Loss: 0.7679709196090698\n",
            "  Batch 9600  of  16875.    Loss: 0.7706225514411926\n",
            "  Batch 9700  of  16875.    Loss: 0.5948556065559387\n",
            "  Batch 9800  of  16875.    Loss: 0.7664138674736023\n",
            "  Batch 9900  of  16875.    Loss: 0.6490340828895569\n",
            "  Batch 10000  of  16875.    Loss: 0.37659648060798645\n",
            "  Batch 10100  of  16875.    Loss: 0.6849950551986694\n",
            "  Batch 10200  of  16875.    Loss: 0.6089110970497131\n",
            "  Batch 10300  of  16875.    Loss: 0.5376966595649719\n",
            "  Batch 10400  of  16875.    Loss: 0.6165385842323303\n",
            "  Batch 10500  of  16875.    Loss: 0.6630843877792358\n",
            "  Batch 10600  of  16875.    Loss: 0.6835961937904358\n",
            "  Batch 10700  of  16875.    Loss: 0.5075899362564087\n",
            "  Batch 10800  of  16875.    Loss: 0.6959897875785828\n",
            "  Batch 10900  of  16875.    Loss: 0.7380319833755493\n",
            "  Batch 11000  of  16875.    Loss: 0.7194621562957764\n",
            "  Batch 11100  of  16875.    Loss: 0.8084670901298523\n",
            "  Batch 11200  of  16875.    Loss: 0.6032328009605408\n",
            "  Batch 11300  of  16875.    Loss: 0.7232393026351929\n",
            "  Batch 11400  of  16875.    Loss: 0.7192480564117432\n",
            "  Batch 11500  of  16875.    Loss: 0.5651258230209351\n",
            "  Batch 11600  of  16875.    Loss: 0.5120792388916016\n",
            "  Batch 11700  of  16875.    Loss: 0.611734926700592\n",
            "  Batch 11800  of  16875.    Loss: 0.5344402194023132\n",
            "  Batch 11900  of  16875.    Loss: 0.6685250401496887\n",
            "  Batch 12000  of  16875.    Loss: 0.525188684463501\n",
            "  Batch 12100  of  16875.    Loss: 0.7386983633041382\n",
            "  Batch 12200  of  16875.    Loss: 0.6549146771430969\n",
            "  Batch 12300  of  16875.    Loss: 0.864063560962677\n",
            "  Batch 12400  of  16875.    Loss: 0.6231706738471985\n",
            "  Batch 12500  of  16875.    Loss: 0.65201735496521\n",
            "  Batch 12600  of  16875.    Loss: 0.5865462422370911\n",
            "  Batch 12700  of  16875.    Loss: 0.552594780921936\n",
            "  Batch 12800  of  16875.    Loss: 0.7080075740814209\n",
            "  Batch 12900  of  16875.    Loss: 0.7841173410415649\n",
            "  Batch 13000  of  16875.    Loss: 0.5974291563034058\n",
            "  Batch 13100  of  16875.    Loss: 0.625817596912384\n",
            "  Batch 13200  of  16875.    Loss: 0.5211597084999084\n",
            "  Batch 13300  of  16875.    Loss: 0.5387225151062012\n",
            "  Batch 13400  of  16875.    Loss: 0.6020327806472778\n",
            "  Batch 13500  of  16875.    Loss: 0.5390629768371582\n",
            "  Batch 13600  of  16875.    Loss: 0.85808265209198\n",
            "  Batch 13700  of  16875.    Loss: 0.6979525089263916\n",
            "  Batch 13800  of  16875.    Loss: 0.7865116000175476\n",
            "  Batch 13900  of  16875.    Loss: 0.5671780109405518\n",
            "  Batch 14000  of  16875.    Loss: 0.7978134155273438\n",
            "  Batch 14100  of  16875.    Loss: 0.5630900859832764\n",
            "  Batch 14200  of  16875.    Loss: 0.6020882725715637\n",
            "  Batch 14300  of  16875.    Loss: 0.6568154096603394\n",
            "  Batch 14400  of  16875.    Loss: 0.6247385144233704\n",
            "  Batch 14500  of  16875.    Loss: 0.7278103232383728\n",
            "  Batch 14600  of  16875.    Loss: 0.6380559802055359\n",
            "  Batch 14700  of  16875.    Loss: 0.6395743489265442\n",
            "  Batch 14800  of  16875.    Loss: 0.7899859547615051\n",
            "  Batch 14900  of  16875.    Loss: 0.6004413366317749\n",
            "  Batch 15000  of  16875.    Loss: 0.6531140208244324\n",
            "  Batch 15100  of  16875.    Loss: 0.5116932392120361\n",
            "  Batch 15200  of  16875.    Loss: 0.6674960255622864\n",
            "  Batch 15300  of  16875.    Loss: 0.7687346339225769\n",
            "  Batch 15400  of  16875.    Loss: 0.5336683392524719\n",
            "  Batch 15500  of  16875.    Loss: 0.4890814423561096\n",
            "  Batch 15600  of  16875.    Loss: 0.6996735334396362\n",
            "  Batch 15700  of  16875.    Loss: 0.6744638681411743\n",
            "  Batch 15800  of  16875.    Loss: 0.8963462114334106\n",
            "  Batch 15900  of  16875.    Loss: 0.587919294834137\n",
            "  Batch 16000  of  16875.    Loss: 0.618744969367981\n",
            "  Batch 16100  of  16875.    Loss: 0.6890520453453064\n",
            "  Batch 16200  of  16875.    Loss: 0.5384463667869568\n",
            "  Batch 16300  of  16875.    Loss: 0.6323415637016296\n",
            "  Batch 16400  of  16875.    Loss: 0.7442958950996399\n",
            "  Batch 16500  of  16875.    Loss: 0.6662877202033997\n",
            "  Batch 16600  of  16875.    Loss: 0.5604320764541626\n",
            "  Batch 16700  of  16875.    Loss: 0.4522210955619812\n",
            "  Batch 16800  of  16875.    Loss: 0.731392502784729\n",
            "Average training loss: 0.6295887255845246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/new/results/model3')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/new/results/token')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4g2E3Zu9jzL",
        "outputId": "1184a787-6421-48ae-a51b-7333211a256b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/new/results/token/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/new/results/token/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/new/results/token/spiece.model',\n",
              " '/content/drive/MyDrive/new/results/token/added_tokens.json',\n",
              " '/content/drive/MyDrive/new/results/token/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text, src_lang):\n",
        "    # Đưa mô hình và dữ liệu vào cùng một thiết bị\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    # Mã hóa văn bản đầu vào\n",
        "    encoded_text = tokenizer(f\"<{src_lang}> {text}\", return_tensors='pt').to(device)\n",
        "\n",
        "    # Dịch văn bản\n",
        "    translated = model.generate(**encoded_text)\n",
        "\n",
        "    # Giải mã văn bản đã dịch\n",
        "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "lSyiwWO-9dgP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}